{
  "hash": "28de1013ef343e7d3e47684d94f66097",
  "result": {
    "markdown": "---\ntitle: \"Cluster computing (at UBC)\"\nformat: revealjs\nknitr: \n  opts_chunk: \n    cache: true\n---\n\n\n\n\n\n## UBC HPC\n\n### 3 potentially useful systems:\n\n1. Department VM\n1. [UBC ARC Sockeye](https://arc.ubc.ca/ubc-arc-sockeye)\n1. [Compute Canada](https://docs.computecanada.ca/wiki/Compute_Canada_Documentation)\n\n\nI've only used 1 and 3. I mainly use 3.\n\n\n### Accessing\n\nAs far as I know, access for students requires \"faculty\" support\n\n1. Email The/Binh. \n1. Possible you can access without a faculty PI.\n1. Email your advisor to ask for an account.\n\n. . .\n\n### The rest of this will focus on 3.\n\n\n\n## Prerequisites\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n1. Command line interface (Terminal on Mac)\n\n2. (optional) helpful to have ftp client. (Cyberduck)\n\n3. [Globus Connect](https://www.globus.org/globus-connect-personal). File transfer approved by CC.\n:::\n\n::: {.column width=\"50%\"}\nUseful CL commands\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-1_2924c2b2a6ac48fd180c82171fde1565'}\n\n```{.bash .cell-code}\ncd ~/path/to/directory\n\ncp file/to/copy.txt duplicated/as/copy1.txt\n\nrm file/to/delete.txt\n\nrm -r dir/to/delete/\n\nls -a # list all files\n```\n:::\n\n:::\n::::\n\n\n\n## How to connect\n\nLogin to a system:\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-2_8ab7f4b793d67bcff4f5c0c0efd4e71b'}\n\n```{.bash .cell-code}\nssh dajmcdon@cedar.computecanada.ca\n```\n:::\n\n\n* Upon login, you're on a \"head\" or \"login\" node. \n* Jobs > 30min will be killed. \n* You can continuously run short interactive jobs.\n\n\n## Rule 1\n\n::: {.callout-tip}\nIf you're doing work for school: run it on one of these machines. \n:::\n\n* Yes, there is overhead to push data over and pull results back.\n* But CC/Sockeye is much faster than your machine.\n* And this won't lock up your laptop for 4 hours while you run the job.\n* It's also a good experience.\n* You can log out and leave the job running. Just log back in to see if it's done (you should _always_ have some idea how long it will take)\n\n\n## Modules\n\n* Once you connect with `ssh`:\n\n* There are no Applications loaded.\n\n* You must tell the system what you want.\n\n* The command is `module load r` or `module load sas`\n\n* If you find yourself using the same [modules](https://docs.computecanada.ca/wiki/Utiliser_des_modules/en#Module_collections_.28Lmod_only.29) all the time:\n\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-3_91db2df314cb192f4250e8ad137e75dd'}\n\n```{.bash .cell-code}\nmodule load StdEnv/2020 r gurobi python # stuff I use\n\nmodule save my_modules # save loaded modules\n\nmodule restore my_modules # on login, load the usual set\n```\n:::\n\n\n\n## Running something interactively\n\n1. Login\n\n2. Load modules\n\n3. Request interactive compute\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-4_1533e3b2bcc4ec3209b4d4d06771f851'}\n\n```{.bash .cell-code}\nsalloc --time=1:0:0 --ntasks=1 --account=def-dajmcdon --mem-per-cpu=4096M\n```\n:::\n\n\nThis says: \n\n* Allocate 1 hour\n\n* On 1 CPU\n\n* For the user `def-dajmcdon` (that's me, accounts start with `def-`)\n\n* 4GB of RAM\n\nThen I would start R\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-5_c97c8ffca78ac9e72599d31dec5958b1'}\n\n```{.bash .cell-code}\nr\n```\n:::\n\n\nAnd run whatever I want. If it takes more than an  hour or needs more than 4GB of memory, it'll quit.\n\n\n\n## Interactive jobs\n\n* Once started they'll just go\n* You can do whatever else you want on your machine\n* But you can't kill the connection\n* So don't close your laptop and walk away\n* This is not typically the best use of this resource.\n* Better is likely [syzygy](http://syzygy.ca/).\n\nAlthough, syzygy has little memory and little storage, so it won't do intensive tasks \n\n_I think your home dir is limited to 1GB_\n\n\n\n## Big memory jobs\n\n* Possible you can do this interactively, but discouraged\n\n\n\n::: {.callout-note}\n## Example\n\n* Neuroscience project\n* Dataset is about 10GB\n* Peak memory usage during analysis is about 24GB\n* Can't do this on my computer\n* Want to offload onto CC.ca\n:::\n\n1. Write a `R`/`python` script that does the whole analysis and saves the output.\n\n2. You need to ask CC to run the script for you.\n\n\n## The scheduler\n\n* While you can log in to CC and \"do stuff\"\n* Resources are limited.\n* There's a process that determines who gets resources when.\n* Technically the `salloc` command we used before requested some resources.\n* It may \"sit\" until the resources you want are available, but probably not long.\n* Anything else has to go through the scheduler.\n* Compute Canada uses the `slurm` scheduler\n\n\n## Example script\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-6_7febb3d6bde2cf42b8d4872184d1eb67'}\n\n```{.bash .cell-code}\n#!/bin/bash\n\n#SBATCH --account=def-dajmcdon\n#SBATCH --job-name=dlbcl-suffpcr\n#SBATCH --output=%x-%j.out\n#SBATCH --error=%x-%j.out\n#SBATCH --time=10:00:00\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=1\n#SBATCH --mem-per-cpu=32G\n\nRscript -e 'source(\"dlbcl-nocv.R\")'\n```\n:::\n\n\n* This asks for 10 hours of compute time with 32GB of memory\n* The `job-name`/`output`/`error` fields are for convenience. \n* If unspecified, I'll end up with files named things like `jobid60607-60650934.out`\n\n\n\n## Submitting and other useful commands\n\n* Suppose that `slurm` script is saved as `dlbcl-slurm.sh`\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-7_55092852f4a3b304e7ce6b6ccf0e8105'}\n\n```{.bash .cell-code}\nsbatch dlbcl-slurm.sh # submit the job to the scheduler\n\nsqueue -u $USER # show status of your jobs ($USER is an env variable)\n\nscancel -u $USER # cancel all your jobs\n\nscancel -t PENDING -u $USER # cancel all your pending jobs\n```\n:::\n\n\n::: {.callout-important}\n1. Jobs inherit environment variables. So if you load modules, then submit, your modules are available to run.\n\n2. On Cedar, jobs cannot run from `~/`. It must be run from `~/scratch/` or `~/projects/`.\n:::\n\n# Really big jobs {background-color=\"#e98a15\" }\n\n\n## Types of jobs\n\n1. Big jobs (need lots of RAM)\n\n2. GPU jobs (you want deep learning, I don't know how to do this)\n\n3. Other jobs with *internal* parallelism (I almost never do this)\n\n4. [Embarrassingly parallel jobs (I do this all the time)]{.secondary}\n\n\n\n## Simple parallelization\n\n- Most of my major computing needs are \"embarrassingly parallel\"\n- I want to run a few algorithms on a bunch of different simulated datasets under different parameter configurations.\n- Perhaps run the algos on some real data too.\n- `R` has packages which are good for parallelization (`snow`, `snowfall`, `Rmpi`, `parallel`)\n- This is how I originally learned to do parallel computing. But these packages are not good for the cluster \n- They're fine for your machine, but we've already decided we're not going to do that anymore.\n\n\n\n## Example of the bad parallelism\n\n[Torque script]{.secondary}\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-8_26709d07745d253aecf4bf6d7e0a2f30'}\n\n```{.bash .cell-code}\n#!/bin/bash  \n#PBS -l nodes=8:ppn=8,walltime=200:00:00\n#PBS -m abe\n#PBS -n ClusterPermute \n#PBS -j oe \n\nmpirun -np 64 -machinefile $PBS_NODEFILE R CMD BATCH ClusterPermute.R\n```\n:::\n\n\n* Torque is a different scheduler. UBC ARC Sockeye uses Torque.\n\n* Looks much like Slurm.\n\n* Here, `ClusterPermute.R` uses `Rmpi` to do \"parallel `lapply`\"\n\n* So I asked for 8 processors on each of 8 nodes.\n\n. . .\n\n[Problem]{.secondary}\n\n* The scheduler has to find 8 nodes with 8 available processors before this job will start. \n\n* This often takes a while, sometimes days.\n\n* But the code doesn't *need* all those things to happen *at the same time* because the jobs don't interact.\n\n\n## `{batchtools}`\n\n* Using `R` (or `python`) to parallelize is inefficient when there's a scheduler in the middle.\n* Better is to actually submit 64 different jobs each requiring 1 node\n* Then each can get out of the queue whenever a processor becomes available.\n* But that would seem to require writing 64 different `slurm` scripts\n\n- `{batchtools}` does this for you, all in `R`\n\n    1. It automates writing/submitting `slurm`/`torque` scripts.\n    2. It automatically stores output, and makes it easy to collect.\n    3. It generates lots of jobs.\n    4. All this from `R` directly.\n    \n\nIt's easy to port across machines/schedulers.\n\nI can test parts (or even run) it on my machine without making changes for the cluster.\n\n\n## Setup `{batchtools}`\n\n1. Create a directory where all your jobs will live (in subdirectories). Mine is `~/`\n\n2. In that directory, you need a template file. Mine is `~/.batchtools.slurm.tmpl` (next slide)\n\n3. Create a configuration file which lives in your home directory. You must name it `~/.batchtools.conf.R`.\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-9_234eb188024aa3bc4aa4778ff7c44ec3'}\n\n```{.r .cell-code}\n# ~/.batchtools.conf.R\ncluster.functions = makeClusterFunctionsSlurm()\n```\n:::\n\n\n\n\n## `~/.batchtools.slurm.tmpl`\n\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-10_b28aee8866223a16640912cdaab07aaf'}\n\n```{.bash .cell-code}\n#!/bin/bash\n\n## Job Resource Interface Definition\n##\n## ntasks [integer(1)]:       Number of required tasks,\n##                            Set larger than 1 if you want to further parallelize\n##                            with MPI within your job.\n## ncpus [integer(1)]:        Number of required cpus per task,\n##                            Set larger than 1 if you want to further parallelize\n##                            with multicore/parallel within each task.\n## walltime [integer(1)]:     Walltime for this job, in seconds.\n##                            Must be at least 60 seconds for Slurm to work properly.\n## memory   [integer(1)]:     Memory in megabytes for each cpu.\n##                            Must be at least 100 (when I tried lower values my\n##                            jobs did not start at all).\n##\n## Default resources can be set in your .batchtools.conf.R by defining the variable\n## 'default.resources' as a named list.\n\n<%\n# relative paths are not handled well by Slurm\nlog.file = fs::path_expand(log.file)\n-%>\n\n#SBATCH --account=def-dajmcdon\n#SBATCH --mail-user=daniel@stat.ubc.ca\n#SBATCH --mail-type=ALL\n#SBATCH --job-name=<%= job.name %>\n#SBATCH --output=<%= log.file %>\n#SBATCH --error=<%= log.file %>\n#SBATCH --time=<%= resources$walltime %>\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=<%= resources$ncpus %>\n#SBATCH --mem-per-cpu=<%= resources$memory %>\n<%= if (array.jobs) sprintf(\"#SBATCH --array=1-%i\", nrow(jobs)) else \"\" %>\n\n## Run R:\n## we merge R output with stdout from SLURM, which gets then logged via --output option\nRscript -e 'batchtools::doJobCollection(\"<%= uri %>\")'\n```\n:::\n\n\n. . .\n\nWhen I'm ready to run, I'll call something like:\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-11_c47e2faa399a6d2a62fd4739ed14c4eb'}\n\n```{.r .cell-code}\nbatchtools::submitJobs(job.ids, resources = list(ncpus=1, walltime=\"24:00:00\", memory=\"32G\"))\n```\n:::\n\n\n\n\n## Workflow\n\n[See the vignette:]{.secondary} `vignette(\"batchtools\")`\n\nor the \n\n[website](https://mllg.github.io/batchtools/articles/batchtools.html)\n\n1. Create a folder to hold your code. Mine usually contains 2 files, one to set up/run the experiment, one to collect results. Code needed to run the experiment lives in an `R` package.\n\n2. Write a script to setup the experiment and submit.\n\n3. Wait.\n\n4. Collect your results. Copy back to your machine etc.\n\n\n\n# Do it {background-color=\"#e98a15\"}\n\n\n## Example 1: Use genetics data to viral load\n\n* An \"extra\" example in a methods paper to appease reviewers\n* Method is: \n    \n    1. apply a special version of PCA to a big (wide) data set\n    1. Do OLS using the top few PCs\n    \n* This is \"principle components regression\" with sparse principle components.\n* Got 413 COVID patients, measure \"viral load\" and gene expression\n* 9435 differentially expressed genes.\n* The method needs to form a 10K x 10K matrix multiple times and do an approximate SVD. Requires 32GB memory. Compute time is ~6 hours.\n* Two tuning parameters: $\\lambda$ and number of PCs\n* Want to do CV to choose, and then use those on the whole data, describe selected genes.\n\n\n## Example 1: Use genetics data to viral load\n\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-12_5c25b1f6ea09ef8401a4f5012f90e9fa'}\n\n```{.r .cell-code}\nlibrary(batchtools)\n\nreg <- makeExperimentRegistry(\"spcr-genes\", packages = c(\"tidyverse\", \"suffpcr\"))\nx <- readRDS(here::here(\"suffpcr-covid\", \"covid_x.rds\"))\ny <- readRDS(here::here(\"suffpcr-covid\", \"covid_y.rds\"))\n\nsubsample = function(data, job, ratio, ...) {\n  n = nrow(data$x)\n  train = sample(n, floor(n * ratio))\n  test = setdiff(seq_len(n), train)\n  list(test = test, train = train)\n}\n\naddProblem(\"cv\", data = list(x=x, y=y), fun = subsample)\naddProblem(\"full\", data = list(x=x, y=y))\n\naddAlgorithm(\n  \"spcr_cv\", \n  fun = function(job, data, instance,...) {\n    fit <- suffpcr(data$x[instance$train,], data$y[instance$train], lambda_min = 0, lambda_max = 1, ...)\n    valid_err <- colMeans(\n      (data$y[instance$test] - as.matrix(predict(fit, newdata = data$x[instance$test,])))^2, \n      na.rm=TRUE\n    )\n    return(list(fit = fit, valid_err = valid_err))\n  }\n)\n\naddAlgorithm(\n  \"spcr_full\",\n  fun = function(job, data, instance,...) suffpcr(data$x, data$y, lambda_max = 1, lambda_min = 0, ...)\n)\n\npdes_cv <- list(cv = data.frame(ratio = .75))\npdes_full <- list(full = data.frame())\nades_cv <- list(spcr_cv = data.frame(d = c(3, 5, 15)))\nades_full <- list(spcr_full = data.frame(d = c(3, 5, 15)))\naddExperiments(pdes_cv, ades_cv, repls = 5L)\naddExperiments(pdes_full, ades_full)\n\nsubmitJobs(findJobs(), resources = list(ncpus = 1, walltime = \"8:00:00\", memory = \"32G\"))\n```\n:::\n\n\n\nEnd up with 18 jobs. \n\n\n## Example 2: Predicting future COVID cases\n\n* Take a few _very simple_ models and demonstrate that some choices make a big difference in accuracy.\n\n* At each time $t$, download COVID cases as observed on day $t$ for a bunch of locations\n\n* Estimate a few different models for predicting days $t+1,\\ldots,t+k$\n\n* Store point and interval forecasts.\n\n* Do this for $t$ every week over a year.\n\n\n## Example 2: Predicting future COVID cases\n\n\n\n::: {.cell hash='cluster-computing_cache/revealjs/unnamed-chunk-13_86e8e11040d75a0ae63b8a8f3b85ba5a'}\n\n```{.r .cell-code}\nfcasters <- list.files(here::here(\"code\", \"forecasters\"))\nfor (fcaster in fcasters) source(here::here(\"code\", \"forecasters\", fcaster))\nregistry_path <- here::here(\"data\", \"forecast-experiments\")\nsource(here::here(\"code\", \"common-pars.R\"))\n\n# Setup the data ----------------------------------------------------\nreg <- makeExperimentRegistry(\n  registry_path,\n  packages = c(\"tidyverse\", \"covidcast\"),\n  source = c(here::here(\"code\", \"forecasters\", fcasters), here::here(\"code\", \"common-pars.R\"))\n)\n\ngrab_data <- function(data, job, forecast_date, ...) {\n  dat <- covidcast_signals(\n    data_sources, signals, as_of = forecast_date, \n    geo_type = geo_type, start_day = \"2020-04-15\") %>% \n    aggregate_signals(format = \"wide\") \n  names(dat)[3:5] <- c(\"value\", \"num\", \"covariate\") # assumes 2 signals\n  dat %>% \n    filter(!(geo_value %in% drop_geos)) %>% \n    group_by(geo_value) %>% \n    arrange(time_value)\n}\naddProblem(\"covidcast_proper\", fun = grab_data, cache = TRUE)\n\n# Algorithm wrappers -----------------------------------------------------\nbaseline <- function(data, job, instance, ...) {\n  instance %>% \n    dplyr::select(geo_value, value) %>% \n    group_modify(prob_baseline, ...)\n}\nar <- function(data, job, instance, ...) {\n  instance %>% \n    dplyr::select(geo_value, time_value, value) %>% \n    group_modify(prob_ar, ...)\n}\nqar <- function(data, job, instance, ...) {\n  instance %>% \n    dplyr::select(geo_value, time_value, value) %>% \n    group_modify(quant_ar, ...)\n}\ngam <- function(data, job, instance, ...) {\n  instance %>% \n    dplyr::select(geo_value, time_value, value) %>%\n    group_modify(safe_prob_gam_ar, ...)\n}\nar_cov <- function(data, job, instance, ...) {\n  instance %>% \n    group_modify(prob_ar_cov, ...)\n}\njoint <- function(data, job, instance, ...) {\n  instance %>% \n    dplyr::select(geo_value, time_value, value) %>% \n    joint_ar(...)\n}\ncorrected_ar <- function(data, job, instance, ...) {\n  instance %>% \n    dplyr::select(geo_value, time_value, num) %>% \n    rename(value = num) %>% \n    corrections_single_signal(cparams) %>% \n    group_modify(prob_ar, ...)\n}\n\naddAlgorithm(\"baseline\", baseline)\naddAlgorithm(\"ar\", ar)\naddAlgorithm(\"qar\", qar)\naddAlgorithm(\"gam\", gam)\naddAlgorithm(\"ar_cov\", ar_cov)\naddAlgorithm(\"joint_ar\", joint)\naddAlgorithm(\"corrections\", corrected_ar)\n\n# Experimental design -----------------------------------------------------\nproblem_design <- list(covidcast_proper = data.frame(forecast_date = forecast_dates))\nalgorithm_design <- list(\n  baseline = CJ(train_window = train_windows, min_train_window = min(train_windows), ahead = aheads),\n  ar = CJ(\n    train_window = train_windows, min_train_window = min(train_windows), \n    lags = lags_list, ahead = aheads\n  ),\n  qar = CJ(\n    train_window = train_windows, min_train_window = min(train_windows),\n    lags = lags_list, ahead = aheads\n  ),\n  gam = CJ(\n    train_window = train_windows, min_train_window = min(train_windows),\n    lags = lags_list, ahead = aheads, df = gam_df\n  ),\n  ar_cov = CJ(\n    train_window = train_windows, min_train_window = min(train_windows), \n    lags = lags_list, ahead = aheads\n  ),\n  joint_ar = CJ(\n    train_window = joint_train_windows, min_train_window = min(joint_train_windows), \n    lags = lags_list, ahead = aheads\n  ),\n  corrections = CJ(\n    train_window = train_windows, min_train_window = min(train_windows),\n    lags = lags_list, ahead = aheads\n  )\n)\n\naddExperiments(problem_design, algorithm_design)\nids <- unwrap(getJobPars()) %>% \n  select(job.id, forecast_date) %>% \n  mutate(chunk = as.integer(as.factor(forecast_date))) %>% \n  select(-forecast_date)\n\n## ~13000 jobs, we don't want to submit that many since they run fast\n## Chunk them into groups by forecast_date (to download once for the group)\n## Results in 68 chunks\n\nsubmitJobs(ids, resources = list(ncpus = 1, walltime = \"4:00:00\", memory = \"16G\"))\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}